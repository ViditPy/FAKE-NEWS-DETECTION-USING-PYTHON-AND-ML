{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News_Project",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mymRq5CfuMSS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd9DNT7zuKl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slw6At2AuZN7",
        "colab_type": "text"
      },
      "source": [
        "**DETECTING \"FAKE NEWS\" FROM A HUGE DATA OF NEWS**\n",
        "In this Dataset thre is a mix of news from which first I am going to manipulate unstructured data into readable format and then taking out the false news from it.\n",
        "\n",
        "The Data Csv has been downloaded from the source(https://data-flair.training/blogs/advanced-python-project-detecting-fake-news/)   and is availabe there.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHnpwV5CvHwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "fac0b5ba-2eef-4858-f66a-757213e1e738"
      },
      "source": [
        "pip install numpy pandas sklearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw0ET3_8vTqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XXoQdnwykw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82rIYhoZxMY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('news.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkIW6ytny2Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c4ba981f-58b5-4c40-dd7d-8406634132ad"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... label\n",
              "0        8476  ...  FAKE\n",
              "1       10294  ...  FAKE\n",
              "2        3608  ...  REAL\n",
              "3       10142  ...  FAKE\n",
              "4         875  ...  REAL\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sglA6kFLzCpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3840955-ad0f-4ae5-822b-ceac521b5f53"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5680, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKc1HmJ9zE7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels =df.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC-DzeDazVIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f7c011c0-503e-421a-dd63-e53c87b21549"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    FAKE\n",
              "1    FAKE\n",
              "2    REAL\n",
              "3    FAKE\n",
              "4    REAL\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G6dl6jWzgNP",
        "colab_type": "text"
      },
      "source": [
        "*Now I am Spliting the dataset into training and testing sets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD3V2Y_VzZzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(df['text'],labels,test_size=0.2,random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0SDJS4D0jYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s0S4xp-1sDh",
        "colab_type": "text"
      },
      "source": [
        "**Let’s initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.**\n",
        "\n",
        "Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg88E2-W2FtL",
        "colab_type": "text"
      },
      "source": [
        "## #DataFlair - Initialize a TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z8BnT1F10PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "534wTQ2z2OWl",
        "colab_type": "text"
      },
      "source": [
        "## DataFlair - Fit and transform train set, transform test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFWbL7Uv17nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
        "tfidf_test=tfidf_vectorizer.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8XKv6HP2tGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU9DaCJC2t5C",
        "colab_type": "text"
      },
      "source": [
        "Next, we’ll initialize a PassiveAggressiveClassifier. This is. We’ll fit this on tfidf_train and y_train.\n",
        "\n",
        "Then, we’ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-i_-wf-2ydm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DataFlair - Initialize a PassiveAggressiveClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyD4O7q27pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a2ff4dbc-e808-4824-dc8c-74320a316be2"
      },
      "source": [
        "pac=PassiveAggressiveClassifier(max_iter=50)\n",
        "pac.fit(tfidf_train,y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
              "                            early_stopping=False, fit_intercept=True,\n",
              "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
              "                            n_jobs=None, random_state=None, shuffle=True,\n",
              "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0AwJURK3FNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af3259fe-6598-414a-f960-11c0d794661a"
      },
      "source": [
        "## DataFlair - Predict on the test set and calculate accuracy\n",
        "\n",
        "\n",
        "y_pred=pac.predict(tfidf_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy: {round(score*100,2)}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 94.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szALZFGU3ehA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6YH5esV3fJj",
        "colab_type": "text"
      },
      "source": [
        "We got an accuracy of 92.82% with this model. Finally, let’s print out a confusion matrix to gain insight into the number of false and true negatives and positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eRcMHtI3gBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e7f992e-b55a-42cc-8f51-9afb4748abc9"
      },
      "source": [
        "## DataFlair - Build confusion matrix\n",
        "\n",
        "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[550,  30],\n",
              "       [ 35, 521]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKifbrv38cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QitmYwix39JC",
        "colab_type": "text"
      },
      "source": [
        "So with this model, we have 589 true positives, 587 true negatives, 42 false positives, and 49 false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxNAcEAS3-Ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0roURgu4BaX",
        "colab_type": "text"
      },
      "source": [
        "**Summary**\n",
        "\n",
        "\n",
        "Today, we learned to detect fake news with Python. We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 92.82% in magnitude.\n",
        "\n",
        "Thanks Vidit Agarwal\n",
        "Ph-9997302747"
      ]
    }
  ]
}